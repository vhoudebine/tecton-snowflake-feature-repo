{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc99f48",
   "metadata": {},
   "source": [
    "# 4. Incremental Backfill Features\n",
    "\n",
    "This tutorial will cover incremental backfill features in Tecton: https://docs.tecton.ai/latest/overviews/framework/feature_views/batch/incremental_backfills.html\n",
    "\n",
    "As you saw in tutorial notebook #2, Tecton has a powerful aggregation framework that allows you to define common time-window aggregation features using a variety of built-in aggregation functions ```sum, count, mean, min, max, stdev_pop, stdev_samp, var_pop, var_samp, first(n), last(n)```. Full list of Snowflake compatible aggregation functions [here](https://docs.tecton.ai/docs/sdk-reference/time-window-aggregation-functions) \n",
    "\n",
    "While the aggregation framework should cover the majority of your feature needs, there might be cases where you need to define your own custom aggregations using Snowflake SQL or Snowpark for Python.  \n",
    "\n",
    "If you need to define your own aggregation features in Tecton when the built-in aggregations don't meet your requirements, you can streamline the process by configuring incremental backfills with the ```incremental_backfills=True``` option.\n",
    "\n",
    "\n",
    "These essentially let us define a feature view as an ETL job for an interval, like daily ETLs, and allow Tecton to run them on the materialization period going forward - and perform a backfill job consisting of repeatedly running historical ETLs as they would have been, until the historical load has been completed.\n",
    "\n",
    "<img src=https://docs.tecton.ai/assets/images/materialization-incremental-backfills-2fd2c382f78f5eea16c95c9af4f6747d.svg width=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec39b95e-9024-4e9c-a466-dca166e604fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tecton[snowflake]==0.6.1\n",
      "  Downloading tecton-0.6.1-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: attrs>=21.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (23.1.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.26.157)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.60.0)\n",
      "Collecting jinja2~=3.0.3 (from tecton[snowflake]==0.6.1)\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.22.3)\n",
      "Requirement already satisfied: pathspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (0.11.1)\n",
      "Requirement already satisfied: pendulum~=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.1.2)\n",
      "Requirement already satisfied: protobuf~=3.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (3.20.3)\n",
      "Requirement already satisfied: pypika~=0.48.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (0.48.9)\n",
      "Requirement already satisfied: pytimeparse in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.1.8)\n",
      "Requirement already satisfied: pandas~=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.5.3)\n",
      "Requirement already satisfied: texttable in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (1.6.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.29.0)\n",
      "Requirement already satisfied: colorama~=0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (0.4.4)\n",
      "Requirement already satisfied: tqdm~=4.41 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (4.65.0)\n",
      "Requirement already satisfied: yaspin<3,>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions~=4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (4.5.0)\n",
      "Requirement already satisfied: pygments>=2.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.15.1)\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (7.3.1)\n",
      "Requirement already satisfied: click~=8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (8.1.3)\n",
      "Requirement already satisfied: typeguard~=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.13.3)\n",
      "Requirement already satisfied: sqlparse in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (0.4.4)\n",
      "Requirement already satisfied: semantic-version in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tecton[snowflake]==0.6.1) (2.10.0)\n",
      "Collecting snowflake-connector-python[pandas]~=2.8 (from tecton[snowflake]==0.6.1)\n",
      "  Using cached snowflake_connector_python-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2~=3.0.3->tecton[snowflake]==0.6.1) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas~=1.0->tecton[snowflake]==0.6.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas~=1.0->tecton[snowflake]==0.6.1) (2023.3)\n",
      "Requirement already satisfied: pytzdata>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pendulum~=2.1->tecton[snowflake]==0.6.1) (2020.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (1.15.1)\n",
      "Requirement already satisfied: cryptography<41.0.0,>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (38.0.4)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (1.3.0)\n",
      "Requirement already satisfied: pyOpenSSL<23.0.0,>=16.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (22.1.0)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (3.18.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (2.8.0)\n",
      "Requirement already satisfied: setuptools>34.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (67.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (2023.5.7)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (3.12.0)\n",
      "Collecting pyarrow<8.1.0,>=8.0.0 (from snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1)\n",
      "  Using cached pyarrow-8.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "Requirement already satisfied: termcolor<3.0,>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yaspin<3,>=0.16->tecton[snowflake]==0.6.1) (2.3.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.157 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3->tecton[snowflake]==0.6.1) (1.29.157)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3->tecton[snowflake]==0.6.1) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3->tecton[snowflake]==0.6.1) (0.6.1)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest->tecton[snowflake]==0.6.1) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest->tecton[snowflake]==0.6.1) (21.3)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest->tecton[snowflake]==0.6.1) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest->tecton[snowflake]==0.6.1) (1.1.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest->tecton[snowflake]==0.6.1) (2.0.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]~=2.8->tecton[snowflake]==0.6.1) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas~=1.0->tecton[snowflake]==0.6.1) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->pytest->tecton[snowflake]==0.6.1) (3.0.9)\n",
      "Installing collected packages: pyarrow, jinja2, snowflake-connector-python, tecton\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 10.0.1\n",
      "    Uninstalling pyarrow-10.0.1:\n",
      "      Successfully uninstalled pyarrow-10.0.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: snowflake-connector-python\n",
      "    Found existing installation: snowflake-connector-python 3.1.0\n",
      "    Uninstalling snowflake-connector-python-3.1.0:\n",
      "      Successfully uninstalled snowflake-connector-python-3.1.0\n",
      "  Attempting uninstall: tecton\n",
      "    Found existing installation: tecton 0.7.2\n",
      "    Uninstalling tecton-0.7.2:\n",
      "      Successfully uninstalled tecton-0.7.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask 2.3.2 requires Jinja2>=3.1.2, but you have jinja2 3.0.3 which is incompatible.\n",
      "snowflake-snowpark-python 1.6.1 requires snowflake-connector-python<4.0.0,>=3.0.4, but you have snowflake-connector-python 2.9.0 which is incompatible.\n",
      "sparkmagic 0.20.5 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "sphinx 7.0.0 requires docutils<0.20,>=0.18.1, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jinja2-3.0.3 pyarrow-8.0.0 snowflake-connector-python-2.9.0 tecton-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tecton[snowflake]==0.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0e7a84-0a19-481e-9d25-b9aabb5b4413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SNOWFLAKE_USER=DEMO_USER\n",
      "env: SNOWFLAKE_PASSWORD=tecton123!\n",
      "env: SNOWFLAKE_ACCOUNT=tectonpartner-tecton_demo_usaa\n"
     ]
    }
   ],
   "source": [
    "#Details were sent in an email\n",
    "%env SNOWFLAKE_USER=DEMO_USER\n",
    "%env SNOWFLAKE_PASSWORD=tecton123!\n",
    "%env SNOWFLAKE_ACCOUNT=tectonpartner-tecton_demo_usaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa5777a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 08/04/2023 05:01:00 PM - numexpr.utils - NumExpr defaulting to 2 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv location: \n",
      "Version: 0.6.1\n",
      "Git Commit: 8cadbebe11bebac828a5103ccaf1ad792f16d50b\n",
      "Build Datetime: 2023-03-15T17:57:29\n"
     ]
    }
   ],
   "source": [
    "# Import Tecton and other libraries\n",
    "import logging\n",
    "import os\n",
    "import tecton\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from datetime import datetime, timedelta, date\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "logging.getLogger('snowflake.connector').setLevel(logging.WARNING)\n",
    "logging.getLogger('snowflake.snowpark').setLevel(logging.WARNING)\n",
    "\n",
    "connection_parameters = {\n",
    "    \"user\": os.environ['SNOWFLAKE_USER'],\n",
    "    \"password\": os.environ['SNOWFLAKE_PASSWORD'],\n",
    "    \"account\": 'tectonpartner-tecton_demo_usaa',\n",
    "    \"warehouse\": \"TRIAL_WAREHOUSE\",\n",
    "    \"role\": \"TRIAL_USER\",\n",
    "    # Database and schema are required to create various temporary objects by tecton\n",
    "    \"database\": \"TECTON\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "conn = snowflake.connector.connect(**connection_parameters)\n",
    "tecton.snowflake_context.set_connection(conn) # Tecton will use this Snowflake connection for all interactive queries\n",
    "\n",
    "\n",
    "# Quick helper function to query snowflake from a notebook\n",
    "# Make sure to replace with the appropriate connection details for your own account\n",
    "def query_snowflake(query):\n",
    "    df = conn.cursor().execute(query).fetch_pandas_all()\n",
    "    return df\n",
    "\n",
    "print(\"dotenv location: \" + find_dotenv())\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e60e6",
   "metadata": {},
   "source": [
    "### Creating an Incremental Backfill Feature\n",
    "https://docs.tecton.ai/0.5/overviews/framework/feature_views/batch/incremental_backfills.html \\\n",
    "Many Tecton features are constructed from pointing Tecton to a history of data values; this is data that typically has the form of: \\\n",
    "`entity_id, timestamp, attrivute_value1, attribute_value2...` \\\n",
    "When presented this way, it is possible to construct many features on the fly for any given point in time.  Some features however must be precomputed ahead of time due to the nature & complexity of how they are constructed, and/or due to the type of aggregations they create across aggregation windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63ef19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x10d3cbaf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = tecton.get_workspace('miket') # replace with your workspace name\n",
    "conn.cursor().execute(\"ALTER SESSION SET TIMEZONE = 'UTC'\") # make sure we're operating in UTC/GMT time for snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a43255",
   "metadata": {},
   "source": [
    "### Feature Definition\n",
    "Currently the declarative Tecton aggregation framework does not include the capability to count distinct items across a time period.  However, that can be constructed via backfill incrementals.  We essentially define how the feature would run within the context of a materialization period, the logic behind it, and the time span to run it over.  Let's define one counting the number of distinct `MERCHANT`s a user has interacted with in the past 2 days and past 30 days.  What would the logic look like if we had interest in understanding this metric at present?  First, let's just take a look at the kind of raw data we'd look at for the past 30 days to count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4d3785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>MERCHANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_402539845901</td>\n",
       "      <td>fraud_Skiles LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_656020174537</td>\n",
       "      <td>fraud_Schuppe, Nolan and Hoeger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_709462196403</td>\n",
       "      <td>fraud_Greenholt, Jacobi and Gleason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_871233292771</td>\n",
       "      <td>fraud_Fahey Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_782510788708</td>\n",
       "      <td>fraud_McCullough LLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID                             MERCHANT\n",
       "0  user_402539845901                     fraud_Skiles LLC\n",
       "1  user_656020174537      fraud_Schuppe, Nolan and Hoeger\n",
       "2  user_709462196403  fraud_Greenholt, Jacobi and Gleason\n",
       "3  user_871233292771                      fraud_Fahey Inc\n",
       "4  user_782510788708                 fraud_McCullough LLC"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    DISTINCT USER_ID\n",
    "    , MERCHANT\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS\n",
    "WHERE\n",
    "    TIMESTAMP >= CURRENT_DATE - INTERVAL '30 DAYS'\n",
    "LIMIT 10;\n",
    "'''\n",
    "df_results = query_snowflake(query)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb233e51",
   "metadata": {},
   "source": [
    "Counting these up we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc76d32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>DSTNCT_MERCHANT_30D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_574612776685</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_916905857181</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_91355675520</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_268514844966</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_724235628997</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID  DSTNCT_MERCHANT_30D\n",
       "0  user_574612776685                  680\n",
       "1  user_916905857181                  657\n",
       "2   user_91355675520                  570\n",
       "3  user_268514844966                  693\n",
       "4  user_724235628997                  692"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    USER_ID\n",
    "    , COUNT(DISTINCT MERCHANT) AS DSTNCT_MERCHANT_30D\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS\n",
    "WHERE\n",
    "    TIMESTAMP >= CURRENT_DATE - INTERVAL '30 DAYS'\n",
    "GROUP BY\n",
    "    USER_ID\n",
    "LIMIT 10;\n",
    "'''\n",
    "df_results = query_snowflake(query)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83985b",
   "metadata": {},
   "source": [
    "We are also interested in counts over the past 2 days.  We can consolidate that into this query as well, nulling out those values past the window of time we're not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4b4c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>DSTNCT_MERCHANT_2D</th>\n",
       "      <th>DSTNCT_MERCHANT_30D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>290</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_268308151877</td>\n",
       "      <td>523</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>511</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_930691958107</td>\n",
       "      <td>559</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_722584453020</td>\n",
       "      <td>646</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID  DSTNCT_MERCHANT_2D  DSTNCT_MERCHANT_30D\n",
       "0  user_212730160038                 290                  568\n",
       "1  user_268308151877                 523                  670\n",
       "2  user_460877961787                 511                  680\n",
       "3  user_930691958107                 559                  670\n",
       "4  user_722584453020                 646                  690"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    USER_ID\n",
    "    --only count the most recent 2 days of the retrieval period\n",
    "    , COUNT(DISTINCT CASE WHEN TIMESTAMP >= DATE_TRUNC('DAY', CURRENT_TIMESTAMP) - INTERVAL '2 DAYS' THEN MERCHANT \n",
    "        ELSE NULL END) AS DSTNCT_MERCHANT_2D\n",
    "    --count entire retrieval period\n",
    "    , COUNT(DISTINCT MERCHANT) AS DSTNCT_MERCHANT_30D  \n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS\n",
    "WHERE\n",
    "    TIMESTAMP >= DATE_TRUNC('DAY', CURRENT_TIMESTAMP) - INTERVAL '30 DAYS'\n",
    "GROUP BY\n",
    "    USER_ID\n",
    "LIMIT 10;\n",
    "'''\n",
    "df_results = query_snowflake(query)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa7b20",
   "metadata": {},
   "source": [
    "This logic is good for retrieving data as of _right now_ - but we need to provide Tecton values as they were at different points in history to correctly time travel for training data set generation.  How often will this job be run?  That metric will also be used to limit start and end times, providing context for the period of time being run.  Eg. if this value is expected to be available daily, then we need to create start and end times for the job that could be used to retrieve what the data looked like on any particular day in the past.  Here we will choose `December 2nd, 2022` - what would the data look like if we pulled it any time during that day?  It should account for data known over the past 30 days, what was known at _December 1st, 2022, 11:59:59.999999_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa20b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>DSTNCT_MERCHANT_2D</th>\n",
       "      <th>DSTNCT_MERCHANT_30D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_574612776685</td>\n",
       "      <td>576</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_91355675520</td>\n",
       "      <td>244</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_916905857181</td>\n",
       "      <td>386</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_884240387242</td>\n",
       "      <td>678</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_699668125818</td>\n",
       "      <td>527</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID  DSTNCT_MERCHANT_2D  DSTNCT_MERCHANT_30D\n",
       "0  user_574612776685                 576                  680\n",
       "1   user_91355675520                 244                  574\n",
       "2  user_916905857181                 386                  658\n",
       "3  user_884240387242                 678                  693\n",
       "4  user_699668125818                 527                  675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    USER_ID\n",
    "    --now this is 2 days from the daily materialization end date\n",
    "    , COUNT(DISTINCT CASE WHEN TIMESTAMP >= '2-Dec-2022'::timestamp_ntz - INTERVAL '2 DAYS' THEN MERCHANT \n",
    "        ELSE NULL END) AS DSTNCT_MERCHANT_2D\n",
    "    , COUNT(DISTINCT MERCHANT) AS DSTNCT_MERCHANT_30D\n",
    "FROM \n",
    "    TECTON_DEMO_DATA.FRAUD_DEMO.TRANSACTIONS\n",
    "WHERE\n",
    "    --materialization start date: '2-Nov-2022'\n",
    "    TIMESTAMP >= '2-Dec-2022'::timestamp_ntz - INTERVAL '30 DAYS'\n",
    "    --materialization end date - everything that happened before '2-Dec-2022'\n",
    "    AND TIMESTAMP < '2-Dec-2022'::timestamp_ntz  \n",
    "GROUP BY\n",
    "    USER_ID\n",
    "LIMIT 10;\n",
    "'''\n",
    "df_results = query_snowflake(query)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023a9f8",
   "metadata": {},
   "source": [
    "### Batch Incremental Feature Example\n",
    "In the feature repo, create a file `features/batch_feature_views/distinct_merchant_counts.py` with the below code.  Some substitutions will be made to base the \n",
    "\n",
    "```python\n",
    "from tecton import batch_feature_view, materialization_context\n",
    "from entities import user\n",
    "from data_sources.transactions import transactions\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "@batch_feature_view(\n",
    "    sources=[transactions],\n",
    "    entities=[user],\n",
    "    mode=\"snowflake_sql\",\n",
    "    online=True,\n",
    "    offline=True,\n",
    "    batch_schedule=timedelta(days=1),\n",
    "    feature_start_time=datetime(2022, 11, 1),\n",
    "    ttl=timedelta(days=1),\n",
    "    incremental_backfills=True,\n",
    ")\n",
    "def distinct_merchant_counts(transactions, context=materialization_context()):\n",
    "    return f'''\n",
    "        SELECT \n",
    "            USER_ID\n",
    "            --2 days from the daily materialization end date\n",
    "            , COUNT(DISTINCT CASE WHEN TIMESTAMP >= TO_TIMESTAMP('{context.end_time}') - INTERVAL '2 DAYS' THEN MERCHANT \n",
    "                ELSE NULL END) AS DSTNCT_MERCHANT_2D\n",
    "            --count for the entire span of data (30 days)\n",
    "            , COUNT(DISTINCT MERCHANT) AS DSTNCT_MERCHANT_30D\n",
    "            --when the data became known and available to us; \n",
    "            --the end of closed period, eg. the end date minus a microsecond, like 12/2/2022 11:59.59.999999\n",
    "            , TO_TIMESTAMP('{context.end_time}') - INTERVAL '1 MICROSECOND' AS TIMESTAMP\n",
    "        FROM \n",
    "            {transactions}\n",
    "        WHERE\n",
    "            --materialization start (inclusive)\n",
    "            TIMESTAMP >= TO_TIMESTAMP('{context.end_time}') - INTERVAL '30 DAYS'\n",
    "            --materialization end date (exclusive)\n",
    "            AND TIMESTAMP < TO_TIMESTAMP('{context.end_time}')\n",
    "        GROUP BY\n",
    "            USER_ID\n",
    "        '''\n",
    "```\n",
    "\n",
    "`tecton apply` this code to the repo, and you can then try this feature out.  Via the run operation, we can pass in a single incremental period and pull back some results, eg. in the case of this daily feature, a materialization context spanning only 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4163fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>DSTNCT_MERCHANT_2D</th>\n",
       "      <th>DSTNCT_MERCHANT_30D</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_268308151877</td>\n",
       "      <td>489</td>\n",
       "      <td>670</td>\n",
       "      <td>2023-08-03 23:59:59.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>493</td>\n",
       "      <td>679</td>\n",
       "      <td>2023-08-03 23:59:59.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>231</td>\n",
       "      <td>569</td>\n",
       "      <td>2023-08-03 23:59:59.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_574612776685</td>\n",
       "      <td>572</td>\n",
       "      <td>681</td>\n",
       "      <td>2023-08-03 23:59:59.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_916905857181</td>\n",
       "      <td>405</td>\n",
       "      <td>656</td>\n",
       "      <td>2023-08-03 23:59:59.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID  DSTNCT_MERCHANT_2D  DSTNCT_MERCHANT_30D  \\\n",
       "0  user_268308151877                 489                  670   \n",
       "1  user_460877961787                 493                  679   \n",
       "2  user_212730160038                 231                  569   \n",
       "3  user_574612776685                 572                  681   \n",
       "4  user_916905857181                 405                  656   \n",
       "\n",
       "                   TIMESTAMP  \n",
       "0 2023-08-03 23:59:59.999999  \n",
       "1 2023-08-03 23:59:59.999999  \n",
       "2 2023-08-03 23:59:59.999999  \n",
       "3 2023-08-03 23:59:59.999999  \n",
       "4 2023-08-03 23:59:59.999999  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = tecton.get_workspace('demo-vince')\n",
    "fv = ws.get_feature_view('distinct_merchant_counts')\n",
    "\n",
    "end_time = datetime.utcnow()\n",
    "end_time = datetime(*end_time.timetuple()[:3])\n",
    "start_time = end_time - timedelta(days=1)\n",
    "\n",
    "fv.run(start_time=start_time, end_time=end_time).to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d436d0-9faa-4812-a4c8-69d315058ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 8, 4, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6986e38",
   "metadata": {},
   "source": [
    "To use ```get_historical_features()```, this type of feature must be materialized.  Tecton will orchestrate a series of past ETL type runs for the periods within the backfill history to materialize the data to the offline store for efficient batch data set retrieval.  Creating a spine dataframe with some dates below, and pointing it to the live prod workspace after it has had time to materialize the data, we can see the values obtained belows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94597cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-12-02 12:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-11-30 03:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-11-15 16:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>2022-12-02 11:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>2022-12-01 01:15:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID                 TIMESTAMP\n",
       "0  user_212730160038 2022-12-02 12:30:00+00:00\n",
       "1  user_212730160038 2022-11-30 03:30:00+00:00\n",
       "2  user_212730160038 2022-11-15 16:00:00+00:00\n",
       "3  user_460877961787 2022-12-02 11:00:00+00:00\n",
       "4  user_460877961787 2022-12-01 01:15:00+00:00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ws = tecton.get_workspace('prod')\n",
    "\n",
    "df_spine = pd.DataFrame.from_records([\n",
    "  {\"USER_ID\": \"user_212730160038\", \"TIMESTAMP\": datetime(2022, 12, 2, 12, 30)},\n",
    "  {\"USER_ID\": \"user_212730160038\", \"TIMESTAMP\": datetime(2022, 11, 30, 3, 30)},\n",
    "  {\"USER_ID\": \"user_212730160038\", \"TIMESTAMP\": datetime(2022, 11, 15, 16, 0)},\n",
    "  {\"USER_ID\": \"user_460877961787\", \"TIMESTAMP\": datetime(2022, 12, 2, 11, 0)},\n",
    "  {\"USER_ID\": \"user_460877961787\", \"TIMESTAMP\": datetime(2022, 12, 1, 1, 15)},\n",
    "])\n",
    "\n",
    "df_spine['TIMESTAMP'] = df_spine['TIMESTAMP'].apply(pd.to_datetime, utc=True)\n",
    "df_spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "474bc24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 12/12/2022 03:58:30 PM - snowflake.snowpark - create_temp_table is deprecated. We still respect this parameter when it is True but please consider using `table_type=\"temporary\"` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DSTNCT_MERCHANT_2D</th>\n",
       "      <th>DSTNCT_MERCHANT_30D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-12-02 12:30:00</td>\n",
       "      <td>232</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-11-30 03:30:00</td>\n",
       "      <td>243</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_212730160038</td>\n",
       "      <td>2022-11-15 16:00:00</td>\n",
       "      <td>276</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_460877961787</td>\n",
       "      <td>2022-12-01 01:15:00</td>\n",
       "      <td>464</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             USER_ID           TIMESTAMP  DSTNCT_MERCHANT_2D  \\\n",
       "0  user_212730160038 2022-12-02 12:30:00                 232   \n",
       "1  user_212730160038 2022-11-30 03:30:00                 243   \n",
       "2  user_212730160038 2022-11-15 16:00:00                 276   \n",
       "3  user_460877961787 2022-12-02 11:00:00                 488   \n",
       "4  user_460877961787 2022-12-01 01:15:00                 464   \n",
       "\n",
       "   DSTNCT_MERCHANT_30D  \n",
       "0                  570  \n",
       "1                  570  \n",
       "2                  568  \n",
       "3                  681  \n",
       "4                  681  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv = ws.get_feature_view('distinct_merchant_counts')\n",
    "\n",
    "fv.get_historical_features(spine=df_spine, timestamp_key=\"TIMESTAMP\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd683c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
